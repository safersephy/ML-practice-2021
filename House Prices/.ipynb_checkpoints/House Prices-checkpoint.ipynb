{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2d95bc6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'lightgbm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/8_/wvr5hnlj5k360g467qxb57qr0000gn/T/ipykernel_897/928688209.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRobustScaler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mXGBRegressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mlightgbm\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRepeatedKFold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'lightgbm'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from scipy.special import boxcox1p\n",
    "from sklearn.preprocessing import StandardScaler,OrdinalEncoder,OneHotEncoder\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from scipy import stats\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from xgboost import XGBRegressor\n",
    "import lightgbm as lgb\n",
    "import warnings\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "from IPython.core.interactiveshell import InteractiveShell \n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "%whos\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13d0cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv(\"data/train.csv\")\n",
    "X_test = pd.read_csv(\"data/test.csv\")\n",
    "X.drop(['GarageYrBlt'], axis=1, inplace=True)\n",
    "X.drop(['Utilities'], axis=1, inplace=True)\n",
    "X_test.drop(['GarageYrBlt'], axis=1, inplace=True)\n",
    "X_test.drop(['Utilities'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926ba50f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdcaf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(36, 36))\n",
    "df_corr = X.corr()\n",
    "\n",
    "sns.heatmap(df_corr,annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9ff3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class cleaner(BaseEstimator, TransformerMixin):\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        X.Electrical = X.Electrical.fillna('SBrkr')\n",
    "        X.BsmtFinSF1 = X.BsmtFinSF1.fillna(0)\n",
    "        X.BsmtFinSF2 = X.BsmtFinSF2.fillna(0)\n",
    "        X.GarageCars = X.GarageCars.fillna(0)\n",
    "        X.GarageArea = X.GarageArea.fillna(0)\n",
    "        X[\"PoolQC\"] = X[\"PoolQC\"].fillna(\"NA\")\n",
    "        X.BsmtQual[(X.BsmtFinSF1 == 0)] = X.BsmtQual[(X.BsmtFinSF1 == 0)].fillna('NA')\n",
    "        X.BsmtCond[(X.BsmtFinSF1 == 0)] = X.BsmtCond[(X.BsmtFinSF1 == 0)].fillna('NA')\n",
    "        X.BsmtCond = X.BsmtCond.fillna('TA')\n",
    "        X.BsmtExposure[(X.BsmtFinSF1 == 0)] = X.BsmtExposure[(X.BsmtFinSF1 == 0)].fillna('NA')\n",
    "        X.BsmtFinType1[(X.BsmtFinSF1 == 0)] = X.BsmtFinType1[(X.BsmtFinSF1 == 0)].fillna('NA')\n",
    "        X.BsmtFinType2[(X.BsmtFinSF2 == 0)] = X.BsmtFinType2[(X.BsmtFinSF2 == 0)].fillna('NA')\n",
    "        X.BsmtFinType2 = X.BsmtFinType2.fillna('Unf')\n",
    "        X[\"MiscFeature\"] = X[\"MiscFeature\"].fillna(\"NA\")\n",
    "        X[\"Alley\"] = X[\"Alley\"].fillna(\"NA\")\n",
    "        X[\"Fence\"] = X[\"Fence\"].fillna(\"NA\")\n",
    "        X[\"FireplaceQu\"] = X[\"FireplaceQu\"].fillna(\"NA\")\n",
    "        X['MSSubClass'] = X['MSSubClass'].fillna(\"NA\")\n",
    "        for col in ('GarageType', 'GarageFinish', 'GarageQual', 'GarageCond'):\n",
    "            X[col] = X[col].fillna('NA')\n",
    "\n",
    "        #Group by neighborhood and fill in missing value by the median LotFrontage of all the neighborhood\n",
    "        X[\"LotFrontage\"] = X.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(\n",
    "        lambda x: x.fillna(x.median()))\n",
    "\n",
    "        X.MasVnrArea = X.MasVnrArea.fillna(0)\n",
    "        X.MasVnrType = X.MasVnrType.fillna('None')\n",
    "        X.KitchenQual = X.KitchenQual.fillna('TA')\n",
    "        X.Functional = X.Functional.fillna('Typ')\n",
    "        X.BsmtUnfSF = X.BsmtUnfSF.fillna(0)\n",
    "        X.TotalBsmtSF = X.TotalBsmtSF.fillna(0)\n",
    "        X.BsmtFullBath = X.BsmtFullBath.fillna(0)\n",
    "        X.BsmtHalfBath = X.BsmtHalfBath.fillna(0)\n",
    "\n",
    "        #feature engineering for the Neighborhood\n",
    "        X.loc[(X.Neighborhood == 'NridgHt') | (X.Neighborhood == 'NoRidge'), ['GoodNBH']] = 1\n",
    "        X.GoodNBH = X.GoodNBH.fillna(0)\n",
    "        X = X.drop(['Neighborhood'], axis=1)\n",
    "\n",
    "        #Drop Categoricals that cannot be one hotted, and also not ordinally encoded\n",
    "        X['Exterior1st'] = X['Exterior1st'].fillna(X['Exterior1st'].mode()[0])\n",
    "        X['Exterior2nd'] = X['Exterior2nd'].fillna(X['Exterior2nd'].mode()[0])\n",
    "\n",
    "        X['MSZoning'] = X['MSZoning'].fillna(X['MSZoning'].mode()[0])\n",
    "        X['SaleType'] = X['SaleType'].fillna(X['SaleType'].mode()[0])\n",
    "\n",
    "        #Convert data thats really categorical\n",
    "        X['MSSubClass'] = X['MSSubClass'].apply(str) \n",
    "        X['OverallQual'] = X['OverallQual'].astype(str)  \n",
    "        X['OverallCond'] = X['OverallCond'].astype(str)    \n",
    "        X['YrSold'] = X['YrSold'].astype(str)\n",
    "        X['MoSold'] = X['MoSold'].astype(str)\n",
    "        X['TotalSF'] = X['TotalBsmtSF'] + X['1stFlrSF'] + X['2ndFlrSF']       \n",
    "        \n",
    "        return X\n",
    "\n",
    "\n",
    "class unskew(BaseEstimator, TransformerMixin):\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        \n",
    "        skewed_features = ['MiscVal','PoolArea','LotArea','3SsnPorch','LowQualFinSF', 'KitchenAbvGr','BsmtFinSF2','BsmtHalfBath','ScreenPorch','EnclosedPorch','MasVnrArea','OpenPorchSF','WoodDeckSF' ,'LotFrontage','BsmtUnfSF','1stFlrSF' ,'GrLivArea','2ndFlrSF']\n",
    "        lam = 0.15\n",
    "        for feat in skewed_features:\n",
    "            X[feat] = boxcox1p(X[feat], lam)\n",
    "        \n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9ebebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class df_Ord(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self,cols = [] ,cats = []):\n",
    "        self.ord = None\n",
    "        self.cols = cols\n",
    "        self.cats = cats\n",
    "      \n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        if self.cats == []:\n",
    "            self.ord = OrdinalEncoder(categories=\"auto\")\n",
    "        else:\n",
    "            self.ord = OrdinalEncoder(categories=[self.cats])\n",
    "            \n",
    "        for col in self.cols:\n",
    "\n",
    "            self.ord.fit(X[[col]])        \n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # X has to be a dataframe\n",
    "        Xord = X.copy()\n",
    "        for col in self.cols:\n",
    "            Xord[col] = self.ord.transform(X[[col]])                \n",
    "        Xorded = pd.DataFrame(Xord, index=X.index, columns=X.columns)\n",
    "        return Xorded\n",
    "\n",
    "class df_OH(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self,cols = []):\n",
    "        self.OH = None\n",
    "        self.cols = cols\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \n",
    "        self.OH = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "\n",
    "\n",
    "        self.OH.fit(X[self.cols])        \n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "\n",
    "        XOHedcols = pd.DataFrame(self.OH.transform(X[self.cols]))  \n",
    "        XOHedcols.index = X.index\n",
    "        numX = X.drop(self.cols, axis=1)\n",
    "        XOHed = pd.concat([numX,XOHedcols], axis=1)\n",
    "        return XOHed    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc930f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29141060",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "\n",
    "\n",
    "\n",
    "#correcting right Skew of data\n",
    "\n",
    "sns.distplot(X['SalePrice'] , fit=norm);\n",
    "\n",
    "# Get the fitted parameters used by the function\n",
    "(mu, sigma) = norm.fit(X['SalePrice'])\n",
    "print( '\\n mu = {:.2f} and sigma = {:.2f}\\n'.format(mu, sigma))\n",
    "\n",
    "#Now plot the distribution\n",
    "plt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)],\n",
    "            loc='best')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('SalePrice distribution')\n",
    "\n",
    "#Get also the QQ-plot\n",
    "fig = plt.figure()\n",
    "res = stats.probplot(X['SalePrice'], plot=plt)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#We use the numpy fuction log1p which  applies log(1+x) to all elements of the column\n",
    "X[\"SalePrice\"] = np.log1p(X[\"SalePrice\"])\n",
    "\n",
    "#Check the new distribution \n",
    "sns.distplot(X['SalePrice'] , fit=norm);\n",
    "\n",
    "# Get the fitted parameters used by the function\n",
    "(mu, sigma) = norm.fit(X['SalePrice'])\n",
    "print( '\\n mu = {:.2f} and sigma = {:.2f}\\n'.format(mu, sigma))\n",
    "\n",
    "#Now plot the distribution\n",
    "plt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)],\n",
    "            loc='best')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('SalePrice distribution')\n",
    "\n",
    "#Get also the QQ-plot\n",
    "fig = plt.figure()\n",
    "res = stats.probplot(X['SalePrice'], plot=plt)\n",
    "plt.show()\n",
    "\n",
    "#drop outlier\n",
    "X = X.drop(X[(X['GrLivArea']>4000) & (X['SalePrice']<300000)].index)\n",
    "\n",
    "\n",
    "X.dropna(axis=0, subset=['SalePrice'], inplace=True)\n",
    "y = X.SalePrice              \n",
    "X.drop(['SalePrice'], axis=1, inplace=True)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2,\n",
    "                                                                random_state=0)    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60dd3a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Special to solve the early stopper limitation on pipelines\n",
    "pipeXGB = Pipeline([\n",
    "                         ('clean', cleaner())\n",
    "                         ,('ord',df_Ord(cols=['ExterQual','ExterCond','HeatingQC','KitchenQual'], cats=['Po','Fa','TA','Gd','Ex']))\n",
    "                         ,('ord2',df_Ord(cols=['BsmtQual','BsmtCond','FireplaceQu','GarageQual','GarageCond'], cats=['NA','Po','Fa','TA','Gd','Ex']))\n",
    "                         ,('ord3',df_Ord(cols=['PoolQC'], cats=['NA','Fa','TA','Gd','Ex']))\n",
    "                         ,('ord4',df_Ord(cols=['MiscFeature'], cats=['NA','Othr','Shed','Gar2','Elev','TenC']))\n",
    "                         ,('ord5',df_Ord(cols=['Fence'], cats=['NA','MnWw','GdWo','MnPrv','GdPrv']))\n",
    "                         ,('ord6',df_Ord(cols=['Alley'], cats=['NA','Grvl','Pave']))\n",
    "                         ,('ord7',df_Ord(cols=['BsmtExposure'], cats=['NA','No','Mn','Av','Gd']))\n",
    "                         ,('ord8',df_Ord(cols=['BsmtFinType1','BsmtFinType2'], cats=['NA','Unf','LwQ','Rec','BLQ','ALQ','GLQ'])) \n",
    "                         ,('ord9',df_Ord(cols=['CentralAir'], cats=['N','Y'])) \n",
    "                         ,('ord10',df_Ord(cols=['Functional'], cats=['Sal','Sev','Maj2','Maj1','Mod','Min2','Min1','Typ']))\n",
    "                         ,('ord11',df_Ord(cols=['MSSubClass'], cats=['20','30','40','45','50','60','70','75','80','85','90','120','150','160','180','190']))\n",
    "                         ,('ord12',df_Ord(cols=['YrSold']))\n",
    "                         ,('ord13',df_Ord(cols=['MoSold']))\n",
    "                         ,('ord14',df_Ord(cols=['OverallCond']))\n",
    "                         ,('ord15',df_Ord(cols=['OverallQual']))\n",
    "                         ,('ord16',df_Ord(cols=['GarageType']))\n",
    "                         ,('ord17',df_Ord(cols=['GarageFinish']))\n",
    "                         ,('ord18',df_Ord(cols=['Exterior1st']))\n",
    "                         ,('ord19',df_Ord(cols=['Exterior2nd']))                          \n",
    "                         ,('oh1',df_OH(cols=['MSZoning', 'Street', 'LotShape', 'LandContour', 'LotConfig', 'LandSlope', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'MasVnrType', 'Foundation', 'Heating', 'Electrical', 'PavedDrive', 'SaleType', 'SaleCondition']))\n",
    "                         #,('unskew', unskew())\n",
    "                         ])\n",
    "    \n",
    "# Transform the data\n",
    "X_train = pipeXGB.fit_transform(X_train)\n",
    "X_valid = pipeXGB.transform(X_valid)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3101362b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####LASSO\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "\n",
    "\n",
    "lass = Lasso(alpha =0.0003, random_state=0,max_iter=15000)\n",
    "\n",
    "# define model evaluation method\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# define grid\n",
    "grid = dict()\n",
    "grid['alpha'] = np.arange(0, 0.1, 0.0001)\n",
    "\n",
    "search = GridSearchCV(lass, grid, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1,verbose=2)\n",
    "# perform the search\n",
    "results = search.fit(X_train, y_train)\n",
    "# summarize\n",
    "print('MAE: %.3f' % results.best_score_)\n",
    "print('Config: %s' % results.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502979be",
   "metadata": {},
   "outputs": [],
   "source": [
    "lass2 = Lasso(alpha =0.0006, random_state=0,max_iter=1000)\n",
    "lass2.fit(X_train, y_train)\n",
    "lasspred = lass2.predict(X_valid)   \n",
    "\n",
    "print(\"Pimped Lasso: \" + str(mean_absolute_error(np.expm1(y_valid), np.expm1(lasspred))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3057be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "############RIDGE\n",
    "\n",
    "#https://machinelearningmastery.com/ridge-regression-with-python/\n",
    "\n",
    "ridge = Ridge(alpha =0.0003, random_state=0)\n",
    "\n",
    "# define model evaluation method\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# define grid\n",
    "grid = dict()\n",
    "grid['alpha'] = np.arange(17, 18, 0.001)\n",
    "\n",
    "search = GridSearchCV(ridge, grid, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1,verbose=2)\n",
    "# perform the search\n",
    "results = search.fit(X_train, y_train)\n",
    "# summarize\n",
    "print('MAE: %.3f' % results.best_score_)\n",
    "print('Config: %s' % results.best_params_)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ade876",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge2 = Ridge(alpha =17, random_state=0)\n",
    "\n",
    "ridge2.fit(X_train, y_train)\n",
    "ridgepreds = ridge2.predict(X_valid)   \n",
    "\n",
    "print(\"Pimped Ridge: \" + str(mean_absolute_error(np.expm1(y_valid), np.expm1(ridgepreds))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20598257",
   "metadata": {},
   "outputs": [],
   "source": [
    "######LGBM Bayes\n",
    "\n",
    "import lightgbm as lgb\n",
    "from bayes_opt import BayesianOptimization\n",
    "def search_best_param(X,y,cat_features):\n",
    "    \n",
    "    trainXY = lgb.Dataset(data=X, label=y,categorical_feature = cat_features,free_raw_data=False)\n",
    "    # define the lightGBM cross validation\n",
    "    def lightGBM_CV(\n",
    "        num_leaves, \n",
    "        max_bin,\n",
    "        bagging_freq, \n",
    "        #lambda_l1 \n",
    "        #lambda_l2\n",
    "        ):\n",
    "    \n",
    "        params = {'boosting_type': 'gbdt', 'objective': 'regression', 'metric':'rmse', 'verbose': -1,\n",
    "                  'early_stopping_round':500\n",
    "                 ,'n_estimators': 800\n",
    "                 ,'learning_rate': 0.02\n",
    "                 #,'max_bin': 55\n",
    "                 ,'bagging_fraction' : 0.8\n",
    "                 #,'bagging_freq' : 5\n",
    "                 ,'feature_fraction' : 0.2319\n",
    "                 ,'feature_fraction_seed':9\n",
    "                 ,'bagging_seed':9\n",
    "                 ,'min_data_in_leaf' : 6\n",
    "                 ,'min_sum_hessian_in_leaf' : 11\n",
    "                 ,'num_leaves' : 7\n",
    "                 ,'max_depth':-1\n",
    "                 \n",
    "                 \n",
    "                 }\n",
    "        \n",
    "        #params['max_depth'] = int(round(max_depth))\n",
    "        params[\"num_leaves\"] = int(round(num_leaves))\n",
    "        params[\"max_bin\"] = int(round(max_bin))\n",
    "        params['bagging_freq'] = int(round(bagging_freq))\n",
    "        #params['subsample'] = subsample\n",
    "        #params['colsample_bytree'] = colsample_bytree\n",
    "        #params['lambda_l1'] = max(lambda_l1, 0)\n",
    "        #params['lambda_l2'] = max(lambda_l2, 0)\n",
    "        #params['min_child_weight'] = min_child_weight\n",
    "    \n",
    "        score = lgb.cv(params, trainXY, nfold=5, seed=1, stratified=False, verbose_eval =False, metrics=['rmse'])\n",
    "\n",
    "        return -np.min(score['rmse-mean']) # return negative rmse to minimize rmse \n",
    "\n",
    "    # use bayesian optimization to search for the best hyper-parameter combination\n",
    "    lightGBM_Bo = BayesianOptimization(lightGBM_CV, \n",
    "                                       {\n",
    "                                         # 'max_depth': (3, 30),\n",
    "                                          'num_leaves': (3, 20),\n",
    "                                         \n",
    "                                \n",
    "                                          'max_bin': (20,80),\n",
    "                                          'bagging_freq' :(2, 20),\n",
    "                                         #'lambda_l1': (0, 10)\n",
    "                                          #'lambda_l2': (0, 10),\n",
    "                                         # 'min_child_weight': (2, 100) \n",
    "                                      },\n",
    "                                       random_state = 1,\n",
    "                                       verbose = 1\n",
    "                                      )\n",
    "    np.random.seed(1)\n",
    "    \n",
    "    lightGBM_Bo.maximize(init_points=5, n_iter=15) \n",
    "    \n",
    "    params_set = lightGBM_Bo.max['params']\n",
    "    \n",
    "    # get the params of the maximum target     \n",
    "    max_target = -np.inf\n",
    "    for i in lightGBM_Bo.res: # loop thru all the residuals \n",
    "        if i['target'] > max_target:\n",
    "            params_set = i['params']\n",
    "            max_target = i['target']\n",
    "    \n",
    "    params_set.update({'verbose': -1})\n",
    "    params_set.update({'metric': 'rmse'})\n",
    "    params_set.update({'boosting_type': 'gbdt'})\n",
    "    params_set.update({'objective': 'regression'})\n",
    "\n",
    "    \n",
    "    params_set['num_leaves'] = int(round(params_set['num_leaves']))\n",
    "    params_set['max_bin'] = int(round(params_set['max_bin']))    \n",
    "    params_set['bagging_freq'] = int(round(params_set['bagging_freq']))\n",
    "    #params_set['lambda_l2'] = int(round(params_set['lambda_l2']))\n",
    "\n",
    "    params_set['seed'] = 1 #set seed\n",
    "    \n",
    "    return params_set\n",
    "cat_features = X_train.select_dtypes(['object']).columns.to_list()\n",
    "best_params = search_best_param(X_train,y_train,cat_features)\n",
    "\n",
    "for key, value in best_params.items():\n",
    "    print(key, ' : ', value)\n",
    "\n",
    "train_data=lgb.Dataset(X_train,label=y_train, categorical_feature = cat_features,free_raw_data=False)\n",
    "valid_data=lgb.Dataset(X_valid,label=y_valid, categorical_feature = cat_features,free_raw_data=False)\n",
    "\n",
    "lgbm_best = lgb.train(best_params,\n",
    "                 train_data,\n",
    "                 num_boost_round = 2000,\n",
    "                 valid_sets = valid_data,\n",
    "                 early_stopping_rounds = 500,\n",
    "                 verbose_eval = 100\n",
    "                 )\n",
    "\n",
    "#df = pd.DataFrame(columns=['Id','SalePrice'])\n",
    "#df['Id'] = X_test.Id\n",
    "#df['SalePrice'] = np.expm1(lgbm_best.predict(X_test))\n",
    "#df[['Id','SalePrice']].to_csv('submission1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ad58ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbmpreds = lgbm_best.predict(X_valid)   \n",
    "print(\"Pimped lgbm: \" + str(mean_absolute_error(np.expm1(y_valid), np.expm1(lgbmpreds))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207ed3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbr = XGBRegressor(colsample_bytree=0.7\n",
    "                     , gamma=0.06\n",
    "                     , min_child_weight=8\n",
    "                     , subsample=0.6\n",
    "                     , learning_rate=0.06\n",
    "                     , max_depth=5\n",
    "                     , num_leaves=20\n",
    "                     , n_estimators=400)\n",
    "\n",
    "params = {\n",
    "              \n",
    "             # 'num_leaves': list(range(20, 100,5)),\n",
    "             # 'n_estimators': list(range(50, 1000,50)),\n",
    "\n",
    "          }\n",
    "\n",
    "\n",
    "\n",
    "xgbrcv = GridSearchCV(xgbr, params, cv = 5, scoring='neg_mean_absolute_error',verbose=2)\n",
    "xgbrcv.fit(X_train, y_train)\n",
    "\n",
    "print(xgbrcv.best_params_)\n",
    "print(xgbrcv.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7a987e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xgbrpreds = xgbrcv.predict(X_valid)   \n",
    "print(\"Pimped XGBM: \" + str(mean_absolute_error(np.expm1(y_valid), np.expm1(xgbrpreds))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e3e45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['Id','SalePrice'])\n",
    "df['Id'] = X_test.Id\n",
    "df['SalePrice'] = np.expm1(preds)\n",
    "df[['Id','SalePrice']].to_csv('submission1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02988b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbgamble = lgb.LGBMRegressor(objective='regression',num_leaves=7,\n",
    "                              learning_rate=0.02, n_estimators=800,\n",
    "                              max_bin = 48, bagging_fraction = 0.8,\n",
    "                              bagging_freq = 5, feature_fraction = 0.2319,\n",
    "                              feature_fraction_seed=9, bagging_seed=9,\n",
    "                              min_data_in_leaf =6, min_sum_hessian_in_leaf = 10)\n",
    "\n",
    "\n",
    "lgbgamble.fit(X_train,y_train)\n",
    "lgbgamblepreds = lgbgamble.predict(X_test)\n",
    "print(\"model score: %.3f\" % mean_absolute_error(np.expm1(y_valid), np.expm1(lgbgamblepreds)))\n",
    "    \n",
    "df = pd.DataFrame(columns=['Id','SalePrice'])\n",
    "df['Id'] = X_test.Id\n",
    "df['SalePrice'] = np.expm1(lgbgamblepreds)\n",
    "df[['Id','SalePrice']].to_csv('submission1.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14017994",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c77952",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e82ae2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1509e4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da091301",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressors = [\n",
    "    RandomForestRegressor(n_estimators=800, random_state=0)\n",
    "#    ,XGBRegressor(n_estimators=800, learning_rate=0.03)\n",
    "#    ,XGBRegressor(learning_rate=0.05, max_depth=3,n_estimators=200)\n",
    "    ,Lasso(alpha =0.0003, random_state=0)\n",
    "    ,ElasticNet(alpha=0.0005, l1_ratio=.9, random_state=3)\n",
    "    ,lgb.LGBMRegressor(objective='regression',num_leaves=7,\n",
    "                              learning_rate=0.02, n_estimators=800,\n",
    "                              max_bin = 55, bagging_fraction = 0.8,\n",
    "                              bagging_freq = 5, feature_fraction = 0.2319,\n",
    "                              feature_fraction_seed=9, bagging_seed=9,\n",
    "                              min_data_in_leaf =6, min_sum_hessian_in_leaf = 11)\n",
    "    ]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for regressor in regressors:\n",
    "    pipe = Pipeline([\n",
    "                         ('clean', cleaner())\n",
    "                         ,('ord',df_Ord(cols=['ExterQual','ExterCond','HeatingQC','KitchenQual'], cats=['Po','Fa','TA','Gd','Ex']))\n",
    "                         ,('ord2',df_Ord(cols=['BsmtQual','BsmtCond','FireplaceQu','GarageQual','GarageCond'], cats=['NA','Po','Fa','TA','Gd','Ex']))\n",
    "                         ,('ord3',df_Ord(cols=['PoolQC'], cats=['NA','Fa','TA','Gd','Ex']))\n",
    "                         ,('ord4',df_Ord(cols=['MiscFeature'], cats=['NA','Othr','Shed','Gar2','Elev','TenC']))\n",
    "                         ,('ord5',df_Ord(cols=['Fence'], cats=['NA','MnWw','GdWo','MnPrv','GdPrv']))\n",
    "                         ,('ord6',df_Ord(cols=['Alley'], cats=['NA','Grvl','Pave']))\n",
    "                         ,('ord7',df_Ord(cols=['BsmtExposure'], cats=['NA','No','Mn','Av','Gd']))\n",
    "                         ,('ord8',df_Ord(cols=['BsmtFinType1','BsmtFinType2'], cats=['NA','Unf','LwQ','Rec','BLQ','ALQ','GLQ'])) \n",
    "                         ,('ord9',df_Ord(cols=['CentralAir'], cats=['N','Y'])) \n",
    "                         ,('ord10',df_Ord(cols=['Functional'], cats=['Sal','Sev','Maj2','Maj1','Mod','Min2','Min1','Typ']))\n",
    "                         ,('ord11',df_Ord(cols=['MSSubClass'], cats=['20','30','40','45','50','60','70','75','80','85','90','120','150','160','180','190']))\n",
    "                         ,('ord12',df_Ord(cols=['YrSold']))\n",
    "                         ,('ord13',df_Ord(cols=['MoSold']))\n",
    "                         ,('ord14',df_Ord(cols=['OverallCond']))\n",
    "                         ,('ord15',df_Ord(cols=['OverallQual']))\n",
    "                         ,('ord16',df_Ord(cols=['GarageType']))\n",
    "                         ,('ord17',df_Ord(cols=['GarageFinish']))\n",
    "                         ,('ord18',df_Ord(cols=['Exterior1st']))\n",
    "                         ,('ord19',df_Ord(cols=['Exterior2nd']))                          \n",
    "                         ,('oh1',df_OH(cols=['MSZoning', 'Street', 'LotShape', 'LandContour', 'LotConfig', 'LandSlope', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'MasVnrType', 'Foundation', 'Heating', 'Electrical', 'PavedDrive', 'SaleType', 'SaleCondition']))\n",
    "                         ,('unskew', unskew())\n",
    "                         #,('scaler', RobustScaler())\n",
    "                         ,('model', regressor)\n",
    "                         ])\n",
    "    pipe.fit(X_train, y_train)   \n",
    "    print(regressor)\n",
    "    \n",
    "    preds = pipe.predict(X_valid)\n",
    "    print(\"model score: %.3f\" % mean_absolute_error(np.expm1(y_valid), np.expm1(preds)))\n",
    "    \n",
    "    \n",
    "    df = pd.DataFrame(columns=['Id','SalePrice'])\n",
    "df['Id'] = X_valid.Id\n",
    "df['SalePrice'] = np.expm1(preds)\n",
    "df[['Id','SalePrice']].to_csv('submission1.csv', index=False)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
